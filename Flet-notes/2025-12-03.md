trasformazioni: per mantenere correttezza semantica del loop ma poterlo parallelizzare

## Loop skewing
Another technique involves the rearrangement of the loop body statements.

```c
for (int i=1; i<N; i++) {
	y[i] = f(x[i-1]); // S1
	x[i] = x[i] + c[i]; // S2
}
```

Solution: make sure the statements that consume the calculated values cause the dependence, use values generated during the same iteration
(non usare i-1)

```c
y[1] = f(x[0]);
for (int i=1; i<N; i++) {
	x[i] = x[i] + c[i];
	y[i+1] = f(x[i]);
}
x[N-1] = x[N-1] + c[N-1];
```

>[!question] How to do loop skewing?
>>[!tip] Unroll the loop and see the repetition pattern
>
>```c
>y[1] = f(x[0]);
>x[1] = x[1]+c[1];
>y[2] = f(x[1]);
>x[2] = x[2]+c[2];
>...
>y[N-2] = f(x[N-3]);
>x[N-2] = x[N-2]+ c[N-2];
>y[N-1] = f(x[N-2]);
>x[N-1] = x[N-1]+ c[N-1];
>```
>
>li devo raggruppare in 
>```c
>x[1] = x[1]+c[1];
>y[2] = f(x[1]);
>```
>
>quindi prima e ultima iterazione le metto fuori dal ciclo tutte le altre le raggruppo in questo modo dentro

## Partical parallelization
### Iteration space dependency graph
ISDG is made of up of nodes that represent a single execution of the loop body, and edges that represent dependencies

```c
for (int i=1; i<N; i++)
	for (int j=1; j<M; j++)
		data[i][j] = data[i-1][j] + data[i-1][j-1];
```

ragionare sulle dipendenzew in un loop annidato risulta tosto

No edge/dipendencies between nodes on the same row (i.e. we can parallelize the j-loop)

![[Pasted image 20251203143929.png]]

freccie rappresnetano dipendenze tra iterazioni diverse

```c
for (int i=1; i<N; i++)
#pragma omp parallel for
	for (int j=1; j<M; j++)
		data[i][j] = data[i-1][j] + data[i-1][j-1];
```

visto che le dipendenze sono solamente tra livelli diversi, posso parallelizzare il for che non ha dipendenze. in questo caso i nodi sullo stesso livello non hanno dipendenze tra di loro (è indipendente in che ordine li eseguo)

## Refactoring
Refactoring refers to rewriting the loop(s) so that parallelism can be exposed. The ISDG for the following example:
```c
for (int i=1; i<N; i++)
	for (int j=1; j<N; j++)
		data[i][j] = data[i-1][j] + data[i][j-1] + data[i-1][j-1]
```

![[Pasted image 20251203144752.png|500]]

Diagonal sets can be executed in parallel (no edges/dependencies) between nodes in the same diagonal set)

![[Pasted image 20251203144919.png|500]]

abbiamo un loop esterno che va una wave alla volta e andiamo una diagonale alla volta sulla wave

```c
// intuition
for(wave=0 wave<NumWaves; wave++) {
	diag=F(wave);
	#pragma omp parallel for
	for(k=0; k<diag; k++) {
		int i = get_i(diag, k);
		int j = get_j(diag, k);
		data[i][j] = data[i-1][j] + data[i][j-1] + data[i-1][j-1];
	}
}
```

The execution in waves requires a change  of loop variables from the original `i` and `j`

## Fissioning
Fissioning means breaking the loop apart into a sequential and a parallelizable part

```c
s = b[0];
for (int i=1; i<N; i++) {
	a[i] = a[i] + a[i-1]; // S1
	s = s + b[i];
}
```

Becomes
```c
// sequential part
for (int i=1; i<N; i++) {
	a[i] = a[i] + a[i-1]; // S1
}

// parallel part
s = b[0];
#pragma omp parallel for reduction(+:a)
for (int i=1; i<N; i++) {
	s = s + b[i];
}
```

## Algorithm change
If everything else fails, switching the algorithm may be the answer. For example, the Fibonacci sequence:
```c
for (int i=2; i<N; i++) {
	int x = F[i-2]; // S1
	int y = F[i-1]; // S2
	F[i] = x+y;     // S3
}
```

Can be parallelized via Binet’s formula:
$$
F_{n}=
$$

##  Antidependence removal (WAR)

vettore di sola letturea

```c
for (int i=0; i<N-1; i++) {
	a[i] = a[i+1] + c;
}
```

Simple solution, make a copy of a before starting to modify it:
```c
for (int i=0; i<N-1; i++) {
	a2[i] = a[i+1];
}

#pragma omp parallel for
for (int i=0; i<N-1; i++) {
	a[i] = a2[i]+c
}
```

in questo caso non ha molto senso, aumentiamo solamente la complessità

## Output Dependence Removal (WAW)

```c
for (int i=0; i<N; i++) {
	y[i] = a*x[i] + c; // S1
	d = fabs(y[i]);    // S2
}
```

voglio che l’ultima iterazione sia quella che scrive il valore finale di d