## Can we extrapole expectations? Amdahl’s law
Intuition: each program has some part of it which cannot be parallelized (serial fraction $1-a$)

>[!example]
>Reading/writing a file from disk, sending/receiving data over the network, serialization due to lock/unlock, etc.

Amdahl’s law says that the speedup is limited by the serial fraction ($s$)

(la parte con p può essere parallelizzata la parte con s no, (es. in loop per calcolare elemento corrente devo calcolare quello precedente)) per questo non si può mai ottenere lo speedup ideale
![[Pasted image 20251028171035.png|400]]

Amdahl’s law says that the speedup is limited by the serial fraction
$$
T_{\text{parallel}}(p)=(1-\alpha)T_{\text{serial}}+\frac{\alpha T_{\text{seiral}}}{p}
$$

A fraction $0\leq \alpha\leq 1$ can be parallelized. The remaining $1-a$ has to be done sequentially
alpha è la percentuale parallelizzabile

>[!example]
>- if $\alpha\neq 0$, the code can’t be parallelized and $T_{\text{parallel}}(p)=T_{\text{serial}}$
>- if $\alpha=1$, the entire code can be parallelized and $T_{\text{parallel}}(p)=\frac{T_{\text{serial}}}{p}$ (ideal speedup)

speedup
$$
S(p)=\frac{T_{\text{serial}}}{(1-\alpha)T_{\text{serial}}+\frac{\alpha T_{\text{serial}}}{p}}
$$

$$
\lim_{ p \to \infty } S(p)=\frac{1}{1-\alpha}
$$

importante perchè dice limite asintotico a cui possiamo tendere con lo speedup

(to fix)
>[!example]
>- if $60\%$ of the application can be parallelized, $\alpha = 0.6$, which means we can expect a speedup of at most $2.5$
>- if $80\%$ of the application can be parallelized, $\alpha = 0.8$, which means we can expect a speedup of at most $5$
>
>To be able to scale up to $100000$ (è lo speedup) processes, we need to have $\alpha >= 0.99999$

![[Pasted image 20251028172251.png]]

## Gustafon’s law
(al posto di considerare lo strong scaling si usa il weak scaling)

If we consider weak scaling, the parallel fraction increases with the problem size (i.e., the serial time remains constant, but the parallel time increases)

It is also known as scaled speedup
$$
S(n,p)=(1-\alpha)+\alpha p
$$

![[Pasted image 20251028172451.png]]

quando andiamo ad analizzare il weak scaling il carico di lavoro rimane costante

## Amdahl’s law limitations
The serial fraction could get bigger when increasing the number of processor (i.e. the runtime might increase when increasing the number of processors)

![[Pasted image 20251028172559.png]]

## A parallell sorting algorithm

>[!info]
>- $n$ keys and $p=$ comm sz processes
>- $n/p$ keys assigned to each process

No restrictions on which keys are assigned to which processes, when the algorithm terminates:
- the keys assigned to each process should be sorted in (say) incresing order
- if $0\leq q<r<p$, then each key assigned to processo $q$ should be less than or equal to every key assigned to process $r$

```c
void Bubble_sort(
	int a[], // in/out
)
```

## Example: sum between vectors
$$
\begin{align}
x+y&=(x_{0},x_{1},\dots,x_{n-1})+(y_{0},y_{1},\dots,y_{n-1}) \\
&=
\end{align}
$$

### Parallel implementation

```c
void Parallel_vector_sum(
) {
	int local_i;
	
	for (local_i=0; local_i<local_n; local_i++)
		local_z[local_i] = local_x[local_i] + local_y[local_i];
	
	// Parallel_vector_sum
}
```

## Scatter
scatter, dato vettore iniziale, il rank 0 lo divide e manda un pezzetto ad ogni processo
`MPI_Scatter` can be used in a fuction that reads in an entire vector on process 0 but only send the needed components to each of the other processes

scatter_v posso gestire le quantità da inviare ai singoli processi, in scatter il resto viene perso

MPI_IN_PLACE per evitare al rank 


## Gather
(nell’out vengono ordinati per rank, gaso)
Collect all of the components of the vector onto process 0, and then process 0 can process all of the components

## Collectives on matrices
(slide 48)
primo metodo sbagliato perchè dopo le prime quattro righe ho cose a caso
secondo sbagliato pk dopo i primi 4 elementi della prima riga ho cose a caso

terzo ok

metodo migliore è di linearizzare la matrice
