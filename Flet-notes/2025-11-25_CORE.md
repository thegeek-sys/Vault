## CPU: latency oriented design
High clock frequency
Large caches
- convert long latency memory access to short latency cache accesses
Sophisticated control
- branch prediction for reduced branch latency
- out-of-order exectution
- etrc
Powerful ALU (where the computation is done)
- reduced operawtion latency

![[Pasted image 20251125171918.png]]

GPU progettata per ridurra il più possibile il tempo di esecuzione delle istruzioni

## GPUs: throughput oriented design
Moderate clock frequency
Small caches
simple control 
- no branch prediction
- in-order execution
Energy efficient ALUs
- many, long latency but heavily pipelined for high throughput
Require massive member of threads to tollerate latencies
Use high bandwidth interfaces for memory and host data exchange

![[Pasted image 20251125172404.png]]

latenza (quanto tempo ci emtto ad esegue un task) throughput (numero di task eseguite per unità di tempo)

unità di controllo e cache molto piccole. le unità di controllo sono molto più semplcici quindi molte più unità di esecuzione

nella GPU

Quando più è complessa una ALU più è grande l’area che occupa all’interno della GPU

## Architecture of a CUDA-capable GPU
