## Shared memory
On-chip memory

shared memory è condivisa dai core in esecuzione su quell’sm

Can be used as:
- a place to hold frequently used data that would otherwise require a global memory access
- as a way for cores on the same SM to share data

The `__shared__` specifier can be used to indicate that some data must go in the shared on-chip memory rather than on the global memory

>[!info] Shared memory vs. L1 cache
>- both are on-chip. The former is managed by the programmer the latter automatically
>- in some cases, managing it manually (i.e., using the shared memory), might provide better performance (e.g., you do not have any guarantee that the data you need will be in the L1 cache, but with the explicitely managed shared memory, you can control that)

>[!example] 1D stencil
>viene aggiornato in base al valore dei vicini (valore dell’elemento viene aggiornato in base al valore dei vicini)
>
>Considera applying a 1D stencil to a 1D array of elements (each output element is the sum of input elements within a radius)
>
>![[Pasted image 20251210145255.png|350]]
>If radius is 3, then each output element is the sum of 7 input elements
>
>Each thread processes one output element (`blockDim.x` elements per block), so input elements are read several times. For this reason with radius 3, each input element is read seven times

```c
__global__ void stencil_1d(int *in, int *out) {
	// 2*RADIUS padding all'inizio e alla fine
	__shared__ int temp[BLOCK_SIZE + 2 * RADIUS];
	int gindex = threadIdx.x + blockIdx.x * blockDim.x;
	// in posizione threadId.x non sto considerando halo, devo aggiungere radius
	int lindex = threadIdx.x + RADIUS;
	
	// read input elements into shared memory
	temp[index] = in[gindex];
	if (threadIdx.x < RADIUS) {
		temp[lindex-RADIUS] = in[gindex-RADIUS];
		temp[lindex+BLOCK_SIZE] = in[gindex+BLOCK_SIZE]
	}
	
	// apply the stencil
	int result = 0;
	for (int offset=-RADIUS; offset<=RADIUS; offset++)
		result += temp[lindex+offset];
	
	// store the result
	out[gindex] = result;
}
```

