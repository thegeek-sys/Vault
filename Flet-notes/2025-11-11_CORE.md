## OpenMP
OpenMP (multi processing) is an API for shared-memory parallel programming, and is designed for shared-memory systems. System is viewed as a collection of cores or CPUs, all of which have access to main memory.

non confondere con openmpi

OpenMP aims to decompose a sequential program into components that can be executed in parallel and allows an “incremental” conversion of sequential programs into parallel ones, with the assistance of the compiler (molto meno invasivo di MPI)

OpenMP relies on compiler directives for decorating portions of the code that the compiler will attempt to parallelize.

OpenMP programs are globally sequential, locally parallel. Programs follow the fork-join paradigm:
![[Pasted image 20251111172158.png|400]]

### Pragmas
istruzioni che danno delle indicazioni al compilatore (non strettamente legato a openmp e permettono di aggiungere dei comportamenti speciali che non fanno parte dello standard C)

Pragmas are special preprocessor instructions typically added to a system to allow behaviors that aren’t part of the basic C specification.

If the compiler doesn’t support the pragmas ignore them.

```c
#pragma
```

### OpenMP pragmas

```c
#pragma omp parallel
```

Is the most basic parallel directive. The number of threads that run the following structured block of code is determined by the runtime system.

eseguire il blocco di codice successivo in parallelo

```c
#include <stdio.h>
#include <stdlib.h>
#include <omp.h>

void Hello(void);

int main(int argc, char* argv[]) {
	// get number of threads from command line
	int thread_count = strtol(argv[1], NULL, 10);
	
	#pragma omp parallel num_threads(thread_count)
	Hello();
	
	return 0;
}

void Hello(void) {
	int my_rank = omp_get_thread_num();
	int thread_count = omp_get_num_threads();
	
	printf()
}
```

sa che hello deve essere eseguita in parallelo e crea i thread e poi aspetta che tutti abbiano finito di eseguire (fa il join)
get_thread_num mio numero
get_num_threads numero totale di threads

di default esegue numero di thread uguale al numero di core disponibili
`num_threads(thread_count)` è una clausola e specifica che deve creare esttamente `thread_count` threads

```bash
gcc -g -Wall -fopenmp -o omp_hello omp_hello.c
./omp_hello 4
```

l’ordine in cui le stampe vengono fatte è casuale (dipende da come il so decide di schedulare i thread)

### Thread Team Size Control
**Universally**
via the `OMP_NUM_THREADS` environmental variable

>[!example]
>```c
>$ echo ${OMP_NUM_THREADS} # to query the value
>$ export OMP_NUM_THREADS=4 # to set it in BASH
>```

**Program level** 
via the `omp_set_num_threads` function, outside an OpenMP construct.

**Pragma level** 
via the `num_threads` clause

se univeralmente 8 ma pragma 4, i restanti 4 vengono sospesi

Precedence:
- universally
- program level
- pragma level

The `omp_get_num_threads` call returns the active threads in a parallel region. If it is called in a sequential part it returns 1.
The `omp_get_thread_num` returns the id of the calling thread (similar to the rank in MPI)

#### A process forking and joining two threads
![[Pasted image 20251111174218.png]]

non posso andare avanti con l’esecuzione se non hanno terminato tutti i threads

### clause
A clause is some text that modifies a directive (num_thread modifica la direttiva di openmp)

>[!warning]
>- there may be system-defined limitations on the number of threads that a program can start
>- the OpenMP standard doesn’t guarantee that this will actually start `thread_count` threads
>- most current systems can start hundreds or even thousends of threads
>- unless we’re trying to start a lot of threads, we will almost always get the desired number of threads
>- after a block is completed, there is an implicit barrier (viene fatto il join)

### Parallel construct
![[Pasted image 20251111174817.png]]

se sono specificati 8 thread, ne vengono creati 8-1=7 (il master è uno di quelli)

```c
#include <stdio.h>
#include <omp.h>

int main() {
	printf("only master thread here");
	
	#pragma omp parallel
	{
		int tid = 
	}
}
```

se creo una variabile all’interno della parte del thread, viene creata da tutti i threads
se invece fosse fuori una modifica viene vista da tutti


In case the compiler doesn’t support OpenMP
runna le righe solo se è installato
```c
#ifdef _OPENMP
#include <omp.h>
#endif
```

```c
# ifdef _OPENMP
int my_rank = omp_get_thread_num ( );
int thread_count = omp_get_num_threads ( );
# else
int my_rank = 0;
int thread_count = 1;
# endif
```

## The trapezoidal rule
![[Pasted image 20251111175640.png]]

### Assignment of trapezoids to threads
![[Pasted image 20251111175703.png|400]]

Unpredictable results when two (or more) threads attempt to simultaneously execute:

```c
global_result += my_result;
```

potrei perdermi delle modifiche

fare la sezione critica è il modo più semplice in assoluto, ci sono dei modi più avanzati per farlo

## Variables scope
### Scope
In seria programming, the scope of a variable consists of those parts of a program in which the variable can be used

In OpenMP, the scope of a variable refers to the set of threads that can access the variable in a parallel block.

### Scope in OpenMP

```c
...
int x; // shared
#pragma omp parallel
{
	int y; // private
	...
}
...
```

## Reduction operators
A reduction operator is a binary operation (such as addition or multiplication) and is a computation that repeatedly applies the same reduction operator to a sequence of operands in order to get a single result

All of the intermediate results of the operation should be stored in the same variable: the reduction variable.

A reduction clause can be added to a parallel directive

```c
reduction(<operator>: <variable list>)
```

\<variable  list\> dove va scritto il valore

```c
global_result = 0.0;
#pragma omp parallel num_threads(thread_count) \
	reduction(+: global_result)
global_result += Local_trap(double a, double b, int n);
```

>[!warning]  If I do not specify the reduction clause I would have a race condition

## Reduction
The private variables created for a reduction clause are initialized to the *identity value* for the operator. For example of the operator is multiplication, the private variables would be initialized to $1$

ogni thread si farà una variabile privata inizializzata al valore identità (moltiplicazione 1, somma 0) e lavora sulla variabile privata, per poi fare la riduzione

The reduction at the end of the parallel section accumulates the *outside value* and the private values computed inside the parallel region.

>[!example]
>```c
>int acc = 6;
>#pragma omp parallel num_threads(5) reduction(* : acc)
>{
>	acc += omp_get_thread_num(); // 1,2,3,4,5 (1+tid)
>	printf("thread %d: private acc is %d\n",omp_get_thread_num(),acc);
>}
>printf("after: acc is %d\n",acc); // acc=720
>```
>
>Output
>```
>id=0 sum = 1
>tid=3 sum = 4
>tid=4 sum = 5
>tid=2 sum = 3
>tid=1 sum = 2
>Final sum = 720
>```


