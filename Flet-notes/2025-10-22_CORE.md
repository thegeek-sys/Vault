## $\verb|MPI_Bcast|$
Data belonging to a single process is sent to all of the processes in the communicator

```c
int MPI_Bcast(
	void*        data_p,      // in/out
	int          count,       // in
	MPI_Datatype datatype,    // in
	int          source_proc, // in
	MPI_Comm     comm         // in
);
```

data_p: rank 0 invia valore tutti gli altri si trovano i dati ricevuti

## $\verb|MPI_Allreduce|$
Conceptually, an `MPI_Reduce` followed by `MPI_Bcast` (ig. compute a global sum and distribute the result to all the processes)

una reduce e poi una broadcast per distribuire tutti i valori

![[Pasted image 20251022142202.png|300]]

```c
int MPI_Allreduce(
	void*        input_data_p,  // in
	void*        output_data_p, // out
	int          count,         // in
	MPI_Datatype datatype,      // in
	MPI_Op       operator,      // in
	MPI_Comm     comm           // in
);
```

The argument list id identical to that for `MPI_Reduce`, except that there is no `dest_process` since all the processes should get the result

![[Pasted image 20251022142701.png|300]]

(non necessariamente poi la reduce verrà fatta in questo modo, è più efficiente in realtà)

>[!question] Is this the best way of doing it?
>Secondo l’immagine questo è il tempo che impiega
>$2\cdot \log_{2}(p)\cdot T_{\text{send}}$ tempo di send e receive approssimate allo stesso tempo (T send)
>
>![[Pasted image 20251022143012.png]]
>This is also known as butterfly pattern (sometimes as recursive distance doubling)
>
>$T=\log_{2}(p)\cdot T_{\text{send}}$
>
>It is two times faster (other algos might be better depending on the data size)

## Revelance of collective algorithms
Widely used in large-scale parallel applications from many domains. Account for a large fraction of the total runtime and is higly relevant for distributed training of deep-learning models

That’s the reason why all the big players are designing their own collective communication library. For example:
- NCCL (NVIDIA)
- RCCL (AMD)
- OnceCCL (Intel)
- MSCCL (Microsoft)
- …

Give a collective (eg. `MPI_Reduce`), how to select the best algorithm?
- automatically through heuristic
- manually
- MPI implementations such as Open MPI do not make assumption on the underlying hardware 

It is an active research area, both from algorithmic and implementations standpoints

## Performance evaluation
## Elapsed parallel time

```c
double MPI_Wtime(void);
```

Returns the number of seconds that have elapsed since some time in the past

```c
double start, finish;
// ...
start = MPI_Wtime():
// code to be timed
// ...
finish = MPI_Wtime();
printf("Proc %d > Elapsed time = %e seconds\n", my_rank, finish-start);
```

misuriamo i tempi di ciascun rank e prendiamo il tempo impiegato dal processo più lento

```c
double local_start, local_finish, local_elapsed, elapsed;
// ...
local_start = MPI_Wtime():
// code to be timed
// ...
local_finish = MPI_Wtime();
local_elapsed = local_finish-local_start;
MPI_Reduce(&local_elapsed, &elapsed, 1, MPI_DOUBLE, MPI_MAX, 0, comm);

if(my_rank==0) {
	printf("Elapsed time = %e seconds\n", elapsed);
}
```

ma anche questo tempo non è necessariamente corretto dato che potrebbe accadere che un processo ci metta molto perché ad esempio sta aspettando una receive, bisogna fare tanti test

MPI_Barrier serve per stoppare tutti i processi in un dato punto

>[!question] Is one run/measurement enough?
>No, performance data is not deterministic
>
>>[!example]
>>If you run your application 100 times, you will get 100 different runtimes (this is also known as *noise*)
>
>>[!question] Why?
>>- on a given compute node, interference from other applications and/or operating system (context switched, cache pollution, etc.) 
>>- across multiple nodes, interference on the network (is a resource shared among multiple nodes and applications)

